{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import errno\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "from torrequest import TorRequest\n",
    "import sys\n",
    "\n",
    "torpassword = 'truenews05101991'\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "from mtranslate import translate\n",
    "from slugify import slugify\n",
    "from goose3 import Goose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ARTICLE_COUNT_LIMIT_PER_KEYWORD': 300,\n",
      " 'LINKS_POST_PROCESSING_CLEAN_HTML_RATIO_LETTERS_LENGTH': 0.33,\n",
      " 'LINKS_POST_PROCESSING_NUM_THREADS': 8,\n",
      " 'RUN_POST_PROCESSING': 1,\n",
      " 'SLEEP_TIME_EVERY_TEN_ARTICLES_IN_SECONDS': 1}\n"
     ]
    }
   ],
   "source": [
    "from constants import *\n",
    "\n",
    "NUMBER_OF_CALLS_TO_GOOGLE_NEWS_ENDPOINT = 0\n",
    "\n",
    "GOOGLE_NEWS_URL = 'https://www.google.co.jp/search?q={}&hl=eng&source=lnt&tbs=cdr%3A1%2Ccd_min%3A{}%2Ccd_max%3A{}&tbm=nws&start={}'\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "def parallel_function(f, sequence, num_threads=None):\n",
    "    from multiprocessing import Pool\n",
    "    pool = Pool(processes=num_threads)\n",
    "    print(f, sequence)\n",
    "    result = pool.map(f, sequence)\n",
    "    cleaned = [x for x in result if x is not None]\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forge_url(q, start, year_start, year_end):\n",
    "    global NUMBER_OF_CALLS_TO_GOOGLE_NEWS_ENDPOINT\n",
    "    NUMBER_OF_CALLS_TO_GOOGLE_NEWS_ENDPOINT += 1\n",
    "    return GOOGLE_NEWS_URL.format(q.replace(' ', '+'), str(year_start), str(year_end), start)\n",
    "\n",
    "\n",
    "def extract_links(content):\n",
    "    soup = BeautifulSoup(content, 'html.parser')  # _sQb top _vQb _mnc\n",
    "    links_list = [(v.attrs['href'], \"\".join([str(x) for x in v.contents]) ) \\\n",
    "\tfor v in soup.find_all('a', {'class': ['l lLrAF', 'RTNUJf']})]\n",
    "    dates_list = [v.text for v in soup.find_all('span', {'class': ['f nsa fwzPFf', 'nsa fwzPFf f']})]\n",
    "    output = []\n",
    "    logging.debug('Link List : {}'.format(str(links_list)))\n",
    "    logging.debug('Date List : {}'.format(str(dates_list)))\n",
    "    for (link, date) in zip(links_list, dates_list):\n",
    "        output.append((link[0], link[1], date))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-d3aedf4d6d08>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-d3aedf4d6d08>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    logging.debug('Extract Links : {}'.format(str(links)))\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def google_news_run(keyword, limit=10, year_start=2010, year_end=2019, debug=True, sleep_time_every_ten_articles=0):\n",
    "    num_articles_index = 0\n",
    "    ua = UserAgent()\n",
    "    result = []\n",
    "    while num_articles_index < limit:\n",
    "        url = forge_url(keyword, num_articles_index, year_start, year_end)\n",
    "        if debug:\n",
    "            logging.debug('For Google -> {}'.format(url))\n",
    "            logging.debug('Total number of calls to Google = {}'.format(NUMBER_OF_CALLS_TO_GOOGLE_NEWS_ENDPOINT))\n",
    "        headers = {'User-Agent': ua.chrome}\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=20)\n",
    "            links = extract_links(response.content)\n",
    "            logging.debug('Extract Links : {}'.format(str(links)))\n",
    "\n",
    "            nb_links = len(links)\n",
    "            if nb_links == 0 and num_articles_index == 0:\n",
    "                \"\"\"raise Exception(\n",
    "                    'No results fetched. Either the keyword is wrong '\n",
    "                    'or you have been banned from Google. Retry tomorrow '\n",
    "                    'or change of IP Address.')\"\"\"\n",
    "        logging.debug('No results')\n",
    "\t\trequests.reset_identity()\n",
    "\t\tlogging.debug('IP Changed. Retrying ....')\n",
    "\t\tresponse = requests.get(url, headers=headers, timeout=20)\n",
    "            \tlinks = extract_links(response.content)\n",
    "            \tlogging.debug('{}'.format(links))\n",
    "        nb_links = len(links)\n",
    "        if nb_links == 0 and num_articles_index == 0:\n",
    "            logging.debug('No Links')\n",
    "\n",
    "            if nb_links == 0:\n",
    "                print('No more news to read for keyword {}.'.format(keyword))\n",
    "                break\n",
    "\n",
    "            for i in range(nb_links):\n",
    "                cur_link = links[i]\n",
    "\t\tlogging.debug('Links : {}'.format(str(cur_link)))\n",
    "                logging.debug('TITLE = {}, URL = {}, DATE = {}'.format(cur_link[1], cur_link[0], cur_link[2]))\n",
    "            result.extend(links)\n",
    "        except:\n",
    "\t    print sys.exc_info()\n",
    "            logging.debug('Google news TimeOut. Maybe the connection is too slow. Skipping.')\n",
    "            pass\n",
    "        num_articles_index += 10\n",
    "        if debug and sleep_time_every_ten_articles != 0:\n",
    "            logging.debug('Program is going to sleep for {} seconds.'.format(sleep_time_every_ten_articles))\n",
    "        time.sleep(sleep_time_every_ten_articles)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
