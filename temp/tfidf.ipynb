{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "processed_doc = pickle.load(open('load_words_all_docs_spacy.pkl','rb'))\n",
    "wordSet = processed_doc['wordset']\n",
    "doc = processed_doc['clean_text_doclist']\n",
    "\n",
    "doc_set_all = []\n",
    "for docc in doc:\n",
    "\tdoc_set = sorted(set().union(docc))\n",
    "\tdoc_dict = dict.fromkeys(doc_set, 0)\n",
    "\tfor word in docc:\n",
    "\t\tdoc_dict[word] += 1 \n",
    "\tdoc_set_all.append(doc_dict.copy())\n",
    "\n",
    "# print (\"wordSet  :   \",\" \".join(sorted(wordSet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(tfDict,doc):\n",
    "    doc_count = len(doc)\n",
    "    for word, count in tfDict.items():\n",
    "    \ttfDict[word] = count/doc_count\n",
    "    return tfDict\n",
    "\n",
    "tfdoc = []\n",
    "for i in range(len(doc)):\n",
    "    tfdoc.append(computeTF(doc_set_all[i], doc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(doc_set_all,wordSet):\n",
    "    import math\n",
    "    idfDict = dict.fromkeys(wordSet, 0)\n",
    "    N = len(doc_set_all)\n",
    "    for word in wordSet:\n",
    "        for i in range(N):\n",
    "        \tif word in doc_set_all[i].keys():\n",
    "        \t\tidfDict[word] += 1\n",
    "             \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / val)\n",
    "                        \n",
    "    return idfDict        \n",
    "\n",
    "\n",
    "idfs = computeIDF(doc_set_all,wordSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfdoc, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfdoc.items():\n",
    "        tfidf[word] = round(val*idfs[word],4) #------rounded for error handeling of data(float64)\n",
    "    return tfidf\n",
    "\n",
    "tfidf = []\n",
    "for t in tfdoc:\n",
    "    tfidf.append(computeTFIDF(t, idfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_wordSet = [dict.fromkeys(wordSet, 0)]*len(doc)\n",
    "\n",
    "# these two for loops aren't working the way they are supposed to:\n",
    "# 1)\n",
    "#         for i in range(len(doc)):\n",
    "# \t          tfidf_wordSet[i].update(**tfidf[i])\n",
    "# 2)\n",
    "#         for i in range(len(doc)):\n",
    "# \t          temp = tfidf[i]\n",
    "# \t          tfidf_wordSet[i].update(**temp)\n",
    "# \n",
    "# ------------ the solution ------------------\n",
    "#  \n",
    "#         for i in range(len(doc)):\n",
    "# \t          temp = tfidf[i]\n",
    "# \t          tfidf_wordSet[i] = dict(tfidf_wordSet[i],**temp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i=0 \n",
    "tfidf_final_struc = [] \n",
    "for wrdF in tfidf_wordSet: \n",
    "    temp = tfidf[i] \n",
    "    # print(temp, wrdF) \n",
    "    tfidf_final_struc.append(dict(wrdF, **temp)) \n",
    "    i += 1\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "df = pd.DataFrame(tfidf_final_struc)\n",
    "\n",
    "df.to_csv('sample_tfidf.csv', sep='\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
